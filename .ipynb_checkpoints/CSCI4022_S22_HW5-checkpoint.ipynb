{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='top'></a>\n",
    "\n",
    "# CSCI4022 Homework 5; A-Priori\n",
    "\n",
    "## Due Friday, March 4 at 11:59 pm to Canvas and Gradescope\n",
    "\n",
    "#### Submit this file as a .ipynb with *all cells compiled and run* to the associated dropbox.\n",
    "\n",
    "***\n",
    "\n",
    "Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Any relevant data sets should be available on Canvas. To make life easier on the graders if they need to run your code, do not change the relative path names here. Instead, move the files around on your computer.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Here is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Canvas on writing math in Markdown. **All** of your written commentary, justifications and mathematical work should be in Markdown.  I also recommend the [wikibook](https://en.wikibooks.org/wiki/LaTeX) for LaTex.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do **Kernel $\\rightarrow$ Restart & Run All** as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "- 45 points of this assignment are in problems.  The remaining 5 are for neatness, style, and overall exposition of both code and text.\n",
    "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "- There is *not a prescribed API* for these problems.  You may answer coding questions with whatever syntax or object typing you deem fit.  Your evaluation will primarily live in the clarity of how well you present your final results, so don't skip over any interpretations!  Your code should still be commented and readable to ensure you followed the given course algorithm.\n",
    "- There are two ways to quickly make a .pdf out of this notebook for Gradescope submission.  Either:\n",
    " - Use File -> Download as PDF via LaTeX.  This will require your system path find a working install of a TeX compiler\n",
    " - Easier: Use File ->  Print Preview, and then Right-Click -> Print using your default browser and \"Print to PDF\"\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Extra Credit](#p3) |\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import itertools as it #may use for .combinations/similar, if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p1'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 1 (Practice: Candidate Items; 20 pts)\n",
    "\n",
    "In the A-Priori algorithm, there is a step in which we create a candidate list of frequent itemsets of size $k+1$ as we prune the frequent itemsets of size $k$.  This this problem we will create two functions to do that formally.\n",
    "\n",
    "#### Part A:\n",
    "\n",
    "There are two types of data objects in which we might be holding the frequency counts of itemsets.  If $k=2$, they may be stored in a triangular array.  Create a function `Cand_Trips` that takes a triangular array and returns all valid candidate triples as a list.  Recall that the itemset $\\{i,j,k\\}$ is only a candidate if all 3 of the itemsets in $\\{\\{i,j\\}, \\{i,k\\}, \\{k,j\\}\\}$ are frequent.\n",
    "\n",
    "Some usage notes:\n",
    "\n",
    "- The first input argument is `triang_counts`,  a zero-indexed triangular (numeric) array, by same convention as introduced in class.\n",
    "- The second input argument is the positive integer support threshold `s`.\n",
    "- The underlying itemset is 0-indexed, so e.g. `[0,1,3]` is a valid triple.\n",
    "- You should not convert the input list `triang_counts` into a list of triples as part of your function.\n",
    "- The return array `candidates` should be a list of 3-index lists of the item numbers of the triples.  So a final answer for some input might be:\n",
    "\n",
    "`cand_trips` =\n",
    "    `[[0,3,4], [1,2,7]]`\n",
    "\n",
    "- An implementation note: there are two fundamentally different ways to think about implementing this function.  Option 1 involves thinking about the elements of `triang_counts` in terms of their locations on the corresponding *triangular matrix*: scan row $i$ for a pair of frequent pairs $\\{\\{i,j\\}, \\{i,k\\}\\}$ and then check if $\\{j,k\\}$ is in fact frequent.  Option 2 scans all of `tri_Counts` for frequent item pairs (the \"pruning\" step) and saves those in some object with their indices, then scans *that* object for candidates.  Both are valid for this problem, but option 2 may generalize to higher $k$ better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cand_trips(triang_counts, s):\n",
    "    elements = int((1 + np.sqrt(1 + 8 * len(triang_counts))) / 2) # this is the reverse of int((n - 1) * n / 2) from nb08                                                \n",
    "    pairs = []\n",
    "    candidates = []\n",
    "    counter = 0\n",
    "    for i in range(elements):\n",
    "        for j in range(i + 1, elements):\n",
    "            if(triang_counts[counter] >= s):\n",
    "                pairs.append((i, j))\n",
    "            counter += 1       \n",
    "    \n",
    "    for a in range(len(pairs)):\n",
    "        for b in range(a +  1, len(pairs)):\n",
    "            if(pairs[b][0] in it.chain(pairs[a]) or pairs[b][1] in it.chain(pairs[a])):\n",
    "                for c in range(b + 1, len(pairs)):\n",
    "                    if(pairs[c][0] in it.chain(pairs[a]) or pairs[c][0] in it.chain(pairs[b])):\n",
    "                        if(pairs[c][1] in it.chain(pairs[a]) or pairs[c][1] in it.chain(pairs[b])):\n",
    "                            tempTuples = ((pairs[a]), (pairs[b]), pairs[c])\n",
    "                            out = list(set([item for items in tempTuples for item in items]))\n",
    "                            candidates.append(out)\n",
    "        \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B:\n",
    "\n",
    "A quick test case.  Below is  a matrix $M$ and code including its corresponding the triangular array.  \n",
    "\n",
    "$C=\\begin{bmatrix}\n",
    "\\cdot &10&7&3&2\\\\\n",
    "\\cdot &\\cdot&6&4&3\\\\\n",
    "\\cdot &\\cdot&\\cdot&3&6\\\\\n",
    "\\cdot &\\cdot&\\cdot&\\cdot&0\\\\\n",
    "\\cdot &\\cdot&\\cdot&\\cdot&\\cdot\\\\\n",
    "\\end{bmatrix}$\n",
    " \n",
    "Input the given list into your function to verify that it returns the correct valid triples at $s=1$ and $s=6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For s>=6, candidate: [[0, 1, 2]]\n",
      "For s>=1, candidates: [[0, 1, 2], [0, 1, 3], [0, 1, 4], [0, 2, 3], [0, 2, 4], [1, 2, 3], [1, 2, 4]]\n"
     ]
    }
   ],
   "source": [
    "triang_counts=[10,7,3,2,6,4,3,3,6 ,0]\n",
    "\n",
    "print('For s>=6, candidate:', cand_trips(triang_counts, 6))\n",
    "print('For s>=1, candidates:', cand_trips(triang_counts, 1))\n",
    "\n",
    "#(10,7,3,2,6,4,3,3,6,0)\n",
    "#((0, 1), (0, 2), (1, 2), (2, 4))\n",
    "#(0, 1, 2)\n",
    "\n",
    "#cand_trips(triang_counts, 1) returns all the possible triples except those that contain BOTH items 3 and 4.\n",
    "#cand_trips(triang_counts, 6) returns only the triple [[0,1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part C:\n",
    "\n",
    "Suppose instead that our $k=2$ item counts were stored in a list of the form e.g.\n",
    "`pairs_counts` =\n",
    "    `[[0,1,12], [0,2,0], [0,3,11], ..., [7,8,103]]`\n",
    "    \n",
    "Where each element is a triple storing the two item indices and their count, $[i,j,c_{ij}]$. \n",
    "\n",
    "Create a function `cand_trips_list` that takes in a list of pairs counts and returns all valid candidate triples as a list.  \n",
    "\n",
    "Some usage notes:\n",
    "\n",
    "- The first input argument is `pairs_counts`,  a zero-indexed list of triples.\n",
    "- The second input argument is the positive integer support threshold `s`.\n",
    "- The underlying itemset is 0-indexed, so e.g. `[0,1,3]` is a valid triple.\n",
    "- The return array `candidates` should be a list of 3-element lists, as above.\n",
    "\n",
    "You should **not** convert the input list `pairs_counts` into a triangular array as part of your function.  After all, sometimes we use the list format for pairs because it saves memory compared to the triangular array format!  You may be able to borrow heavily from the logic of your first function, though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cand_trips_list(pairs_counts, s):\n",
    "    pairs = []\n",
    "    candidates = []\n",
    "    for pair in pairs_counts:\n",
    "        if(pair[2] >= s):\n",
    "            pairs.append(pair)\n",
    "\n",
    "    for a in range(len(pairs)):\n",
    "        for b in range(a +  1, len(pairs)):\n",
    "            if(pairs[b][0] in it.chain(pairs[a][:-1]) or pairs[b][1] in it.chain(pairs[a][:-1])):\n",
    "                for c in range(b + 1, len(pairs)):\n",
    "                    if(pairs[c][0] in it.chain(pairs[a][:-1]) or pairs[c][0] in it.chain(pairs[b][:-1])):\n",
    "                        if(pairs[c][1] in it.chain(pairs[a][:-1]) or pairs[c][1] in it.chain(pairs[b][:-1])):\n",
    "                            tempTuples = ((pairs[a][:-1], (pairs[b][:-1]), pairs[c][:-1]))\n",
    "                            out = list(set([item for items in tempTuples for item in items]))\n",
    "                            candidates.append(out)    \n",
    "                            \n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part D:\n",
    "\n",
    "Do the test case again.  Below is the list reprentation of the same matrix $M$ from part B.  \n",
    " \n",
    "Input the given list into your function to verify that it returns the correct valid triples at $s=1$ and $s=6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2]]\n",
      "[[0, 1, 2], [0, 1, 3], [0, 1, 4], [0, 2, 3], [0, 2, 4], [1, 2, 3], [1, 2, 4]]\n"
     ]
    }
   ],
   "source": [
    "pairs_counts=[[0,1,10], [0,2,7], [0,3,3], [0,4,2],\\\n",
    "             [1,2,6],[1,3,4], [1,4,3],\\\n",
    "             [2,3,3],[2,4,6],\\\n",
    "             [3,4,0]]\n",
    "print(cand_trips_list(pairs_counts, 6))\n",
    "print(cand_trips_list(pairs_counts, 1))\n",
    "#Check that...\n",
    "#cand_trips(pairs_counts, 1) returns all the possible triples except those that contain BOTH items 3 and 4.\n",
    "#cand_trips(pairs_counts, 6) returns only the triple [[0,1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part E\n",
    "\n",
    "Describe *in words* how you would generalize your code in part D to work for generating candidate quadruples $[i_1, i_2, i_3, i_4]$ from an input list of triples counts (each element of the form $[i, j, k, c_{ijk}]$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Within my if statements, I would add a new comparison for the additional element, which would also require me to add another loop. }$ <br>\n",
    "$\\text{For example, I would have to add another 'or' within all of my if statements which would check to see if pairs[x][2] is in the previous pairs}$ <br>\n",
    "$\\text{I would need another for loop which would be for d in range(c + 1, len(pairs)), within this for loop would be another if statement and would contain the }$ <br>\n",
    "$\\text{tempTuples, out and append lines.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "<a/ id='p2'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 2 (Practice: A-Priori; 25 pts) \n",
    "\n",
    "Consider the recipe data set provided in `recipes.npy` (use `np.load`).  This includes 100,000 recipes from a variety of sources.\n",
    "\n",
    "We want to use the baskets and the ingredients therein (see `ingredients.npy`) to perform an item basket analysis.\n",
    "\n",
    "This data set is small enough to run directly from main memory, so you may do that if you wish.\n",
    "\n",
    "Loading and accessing the data set is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients=np.load('../ingredients.npy', allow_pickle = True)\n",
    "recipes=np.load('../recipes.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 233, 2754,   42,  120,  560,  345,  150, 2081,   12,   21])\n",
      " array([ 198,  249,    2,  194, 1884,  791,  965,  423,   53,   48,  798,\n",
      "          31,  362, 1031,   94,   26,    8])                             ]\n",
      "['salt' 'pepper']\n",
      "['balsamic vinegar' 'boiling water' 'butter' 'cooking spray'\n",
      " 'crumbled gorgonzola' 'currants' 'gorgonzola' 'grated orange' 'kosher'\n",
      " 'kosher salt' 'orange rind' 'parsley' 'pine nuts' 'polenta' 'toasted'\n",
      " 'vinegar' 'water']\n"
     ]
    }
   ],
   "source": [
    "print(recipes[:2]) #list of lists\n",
    "print(ingredients[:2]) #inventory list\n",
    "print(ingredients[recipes[1]]) #to access a recipe by string\n",
    "# print(ingredients[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### a) Since the ingredients file alrady provides integer codes for each of our items, we can move directly into countin via the A-Priori algorithm.  Using the two given files, create a table of frequent single items at 1% support threshold. You may use Python's native classes to set up your lookup functions/tables.\n",
    "\n",
    "Was 1% an appropriate support threshold?  Describe why or why not.  Keep in mind, the goal here is two fold: you want \"actionable\" conclusions, and output that's small enough that you or your grader can make sure that you have the right set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqItems(s):    \n",
    "    occurances = {}\n",
    "    for i in range(0, len(recipes)):\n",
    "        temp = ingredients[recipes[i]]\n",
    "        for j in range(len(temp)):\n",
    "            if(temp[j] in occurances):\n",
    "                occurances[temp[j]] += 1\n",
    "            else:\n",
    "                occurances[temp[j]] = 1\n",
    "                \n",
    "    df = pd.DataFrame.from_dict(occurances, columns = [\"Count\"], orient = 'Index')\n",
    "    dfPruned = df[df[\"Count\"] / len(recipes)  >= s]\n",
    "    dfNewIndicies = dfPruned.reset_index()\n",
    "    dfNewColumns = dfNewIndicies.rename(columns = {\"index\":\"Ingredient\"})\n",
    "    return dfNewColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Ingredient  Count\n",
      "0    basil leaves   1413\n",
      "1          leaves   6635\n",
      "2      mozzarella   2729\n",
      "3        rosemary   2159\n",
      "4          sliced  16155\n",
      "..            ...    ...\n",
      "288  coconut milk   1066\n",
      "289       topping   1066\n",
      "290  strawberries   1544\n",
      "291     asparagus   1009\n",
      "292   dried basil   1181\n",
      "\n",
      "[293 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "thingy = freqItems(.01)\n",
    "print(thingy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{I think that 1% is a bad support threshold because too many ingredients are within the threshold. The larger amount of ingredients which are considered 'frequent' the }$ <br>\n",
    "$\\text{more time it will take to find frequent pairs and may reduce how actionable the conclusions were can derivce from these pairs.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### b) Use A-priori to find all frequent  pairs of items from your set of frequent items in a).  Use whatever support threshold you feel is most appropriate, but make sure your result is readable: you should list the top handful of most frequent pairs, sorted by their prevalence.\n",
    "\n",
    "Report the confidences of the two association rules corresponding to the most frequent item pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ingredient  Count\n",
      "0      butter  29030\n",
      "1       water  19771\n",
      "2      garlic  29054\n",
      "3       olive  20249\n",
      "4   olive oil  20118\n",
      "5       onion  20950\n",
      "6      pepper  38472\n",
      "7        salt  42163\n",
      "8      ground  20674\n",
      "9       sugar  32748\n",
      "10      flour  22696\n"
     ]
    }
   ],
   "source": [
    "def freqPairs(df, arrI, arrR):\n",
    "    pairCount = {}\n",
    "    items = df[\"Ingredient\"].to_list()\n",
    "    pairs = [(a, b) for idx, a in enumerate(items) for b in items[idx + 1:]]\n",
    "    for pair in pairs:\n",
    "        for i in range(len(arrR)):\n",
    "            if(pair[0] in arrI[arrR[i]] and pair[1] in arrI[arrR[i]]):\n",
    "                if pair in pairCount:\n",
    "                    pairCount[pair] += 1\n",
    "                else:\n",
    "                    pairCount[pair] = 1\n",
    "                    \n",
    "    df = pd.DataFrame.from_dict(pairCount, columns = [\"Count\"], orient = 'Index')\n",
    "    dfNewIndicies2 = df.reset_index()\n",
    "    dfNewColumns2 = dfNewIndicies2.rename(columns = {\"index\":\"Pairs\"})\n",
    "    dfNewColumns2.sort_values('Count', inplace = True)\n",
    "    return dfNewColumns2\n",
    "\n",
    "thingy2 = freqItems(.165)\n",
    "print(thingy2)\n",
    "thingy3 = freqPairs(thingy2, ingredients, recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Pairs  Count\n",
      "23      (garlic, salt)  14388\n",
      "6       (butter, salt)  14513\n",
      "51       (salt, flour)  14845\n",
      "46    (pepper, ground)  15020\n",
      "50       (salt, sugar)  15506\n",
      "22    (garlic, pepper)  19276\n",
      "27  (olive, olive oil)  19981\n",
      "45      (pepper, salt)  22494\n"
     ]
    }
   ],
   "source": [
    "print(thingy3.tail(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence of pepper -> salt is 0.5846849656893325\n",
      "The confidence of salt -> pepper is 0.5335009368403577\n"
     ]
    }
   ],
   "source": [
    "lastPair = thingy3.iloc[-1].Pairs\n",
    "\n",
    "pairSupport = (thingy3.iloc[-1].Count / len(recipes)) \n",
    "itemOneFull = thingy2.loc[thingy2[\"Ingredient\"] == lastPair[0]]\n",
    "itemOneValue = itemOneFull.Count.tolist()\n",
    "itemOneSupport = itemOneValue[0] / len(recipes)\n",
    "oneToTwo = pairSupport / itemOneSupport\n",
    "\n",
    "print(\"The confidence of {} -> {} is {}\".format(lastPair[0], lastPair[1], oneToTwo))\n",
    "\n",
    "itemTwoFull = thingy2.loc[thingy2[\"Ingredient\"] == lastPair[1]]\n",
    "itemTwoValue = itemTwoFull.Count.tolist()\n",
    "itemTwoSupport = itemTwoValue[0] / len(recipes)\n",
    "twoToOne = pairSupport / itemTwoSupport\n",
    "\n",
    "print(\"The confidence of {} -> {} is {}\".format(lastPair[1], lastPair[0], twoToOne))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)**\n",
    "\n",
    "Zach has to go to the store and stock his pantry.  He knows that his girlfriend has a (borderline unhealthy to those around her) love of garlic.  What should he purchase to make sure he has in stock?  What are two most frequent $\\{garlic, x\\}$ item pairs, and what are the two most **interesting** $garlic \\to X$ associations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 pairs  interest\n",
      "6  (garlic, olive oil)  0.396891\n",
      "7      (garlic, olive)  0.394428\n",
      "5      (garlic, onion)  0.291837\n"
     ]
    }
   ],
   "source": [
    "def findGarlic(arr, arr2, arr3, term):\n",
    "    garlicPairs = []\n",
    "    interests = []\n",
    "    for row in arr.iterrows():\n",
    "        if term in row[1][0]:\n",
    "            garlicPairs.append(row)\n",
    "                   \n",
    "    for pair in garlicPairs:\n",
    "        if(pair[1][0][1] != \"garlic\"):\n",
    "            row = arr2.loc[arr2[\"Ingredient\"] == pair[1][0][1]]\n",
    "            number = row.Count.tolist()\n",
    "        else:\n",
    "            row = arr2.loc[arr2[\"Ingredient\"] == pair[1][0][0]]\n",
    "            number = row.Count.tolist()\n",
    "\n",
    "        interests.append((pair[1][0], ( (pair[1][1] / len(arr3)) / (number[0] / len(arr3)) ) - (number[0] / len(arr3)) ))\n",
    "    return interests\n",
    "          \n",
    "thingy4 = findGarlic(thingy3, thingy2, recipes, \"garlic\")\n",
    "dfGarlicPairs = pd.DataFrame(thingy4, columns = [\"pairs\", \"interest\"])\n",
    "dfTopTwo = dfGarlicPairs.nlargest(3, [\"interest\"])\n",
    "print(dfTopTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{The most interesting pairs are (garlic, olive oil) and (garlic, olive). However, I am not sure if the garlic and olive pair is a mistake or not because I wouldn't think many recipes}$ <br>\n",
    "$\\text{actually use whole olives in them. I am going to guess my algorithm to find frequent ingridients mistakenly counted all entries that had the ingredient 'olive oil' towards the ingredient 'olive'.}$ <br>\n",
    "$\\text{This would explain why there are more counts of 'olive' than 'olive oil', which otherwise wouldn't make sense.}$ <br>\n",
    "$\\text{So instead, I would say the most interesting pairs are (garlic, olive oil) and (garlic, onion). Which aren't all that interesting but whatever.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p3'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 3 (Extra-Credit: A-Priori with hashing and more baskets; 10 pts each part) \n",
    "\n",
    "The data set in 2 had two very appealing propeties that we typically do **not** assume to be the case:\n",
    "- It came with an ingredient list provided\n",
    "- It was small enough to fit into main memory.\n",
    "\n",
    "To fully implement the model, you can get some extra credit by attempting variants of the data that do not have those properties.  We will tackle each problem individually.  You should answer each problem *in its own, separate notebooks* to ensure you're not using any variables from your solution to problem 2 above.\n",
    "\n",
    "## EC1: A-P with hashing\n",
    "\n",
    "#### EC1a) The file `recipesbying` contains the same data set as in problem 2, but the strings themselves live in each recipe.\n",
    "\n",
    "Create a hash table as in nb08 that hashes each ingredient observed based on its string. In other words, create your own version of what **was** in `ingredients.npy` by creating your own hash and/or lookup functions.\n",
    "Include a check to minimize and fix any collisions, as in nb08.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**EC1b)** Use A-priori to find all frequent items and all frequent pairs of items from your hashed data set in part EC1).  Ensure that the results match those of problem 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EC2: A-P with massive data\n",
    "\n",
    "The `.npz` file `simplified-recipes-1M.npz` contains over 1 million recipes, and is the original source of the 100,000 recipes used in problem 2.  Using this file (and `ingredients.npy`, if desired), use A-priori to find all frequent items and all frequent pairs of items.  However, you should **not** load all of the file into main memory.  Instead, use `np.memmap` or other options to ensure that you never load into main memory more than 100,000 recipes at a time.  Include any processing in your submission, and use the same proportionate support threshold as you did in problem 2.  Do the most common items differ?\n",
    "\n",
    "A few notes: \n",
    "- If you process the data to make it readable in other forms `.npy`, `.csv`, etc., that's fine, but show all processing code in your submission.\n",
    "- For example, if you find `.memmap` hard to get working, you may convert to `.csv` and use `pd.read_csv` with arguments `chunksize` or `skiprows`, `nrows`\n",
    "- You may be able to do the problem with very little additional work if you are clever about how you open the file and read over it.  In this case, set up your \"loop\" over baskets to only go over 100,000 rows of the file at a time, though, and be very explicit as to how you're avoiding the larger objects ever entering main memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
